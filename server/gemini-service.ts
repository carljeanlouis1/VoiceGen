import { log } from "./vite";
import fetch from "node-fetch";

interface GenerateContentOptions {
  prompt: string;
  systemPrompt?: string;
  temperature?: number;
  maxOutputTokens?: number;
  topK?: number;
  topP?: number;
  images?: string[]; // Base64-encoded images
}

interface GenerateContentResult {
  text: string;
  usage?: {
    promptTokens: number;
    responseTokens: number;
    totalTokens: number;
  };
}

/**
 * Generate content using Gemini 2.5 Pro via REST API
 */
export async function generateGeminiContent(options: GenerateContentOptions): Promise<GenerateContentResult> {
  try {
    const apiKey = process.env.GEMINI_API_KEY;
    
    if (!apiKey) {
      throw new Error("GEMINI_API_KEY environment variable is required");
    }
    
    log(`Generating content with Gemini 2.5 Pro: ${options.prompt.substring(0, 100)}...`);
    
    // Prepare the request payload
    const payload: any = {
      contents: [],
      generationConfig: {
        temperature: options.temperature || 0.7,
        maxOutputTokens: options.maxOutputTokens || 4000,
        topK: options.topK || 40,
        topP: options.topP || 0.95,
      }
    };
    
    // Create content parts
    const contentParts: any[] = [{ text: options.prompt }];
    
    // Add images if provided
    if (options.images && options.images.length > 0) {
      for (const imageData of options.images) {
        contentParts.push({
          inlineData: {
            data: imageData,
            mimeType: "image/jpeg",
          },
        });
      }
    }
    
    // Add system prompt if provided
    if (options.systemPrompt) {
      payload.contents = [
        {
          role: "user",
          parts: [{ text: options.systemPrompt }]
        },
        {
          role: "model",
          parts: [{ text: "I'll follow your instructions." }]
        },
        {
          role: "user",
          parts: contentParts
        }
      ];
    } else {
      // Standard request without system prompt
      payload.contents = [
        {
          parts: contentParts
        }
      ];
    }
    
    // Set the API endpoint for the Gemini 2.5 Pro model
    const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-exp-03-25:generateContent?key=${apiKey}`;
    
    // Make the API request
    const response = await fetch(apiUrl, {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify(payload)
    });
    
    if (!response.ok) {
      const errorData = await response.text();
      log(`Gemini API error (${response.status}): ${errorData}`);
      throw new Error(`Gemini API error: ${response.status} - ${errorData}`);
    }
    
    const result = await response.json() as any;
    
    if (!result.candidates || result.candidates.length === 0) {
      throw new Error("No content generated by Gemini API");
    }
    
    // Extract the text from the first candidate
    const generatedText = result.candidates[0].content?.parts?.[0]?.text || "";
    
    return { 
      text: generatedText,
      usage: result.usageMetadata ? {
        promptTokens: result.usageMetadata.promptTokenCount || 0,
        responseTokens: result.usageMetadata.candidatesTokenCount || 0,
        totalTokens: (result.usageMetadata.promptTokenCount || 0) + (result.usageMetadata.candidatesTokenCount || 0)
      } : undefined
    };
  } catch (error: any) {
    log(`Error generating content with Gemini 2.5 Pro: ${error.message || "Unknown error"}`);
    throw new Error(`Failed to generate content: ${error.message || "Unknown error"}`);
  }
}